{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff05afb-8f1b-43d8-900f-bc3a47111117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy\n",
    "import pdfplumber\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637874f4-a306-4a3c-8f39-bfd899d23f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankush Kumar Jaiswal\n",
      "In Progress: 2nd year M.B.A, Business Analytics\n",
      "Amity University Online, Noida\n",
      "Phone : +91 - 9354895519\n",
      "Email : jaiswalank1999@gmail.com\n",
      "Linkedin : https://www.linkedin.com/in/ankush-kumar-jaiswal-196937200\n",
      "Github : https://github.com/Ankush-Kumar-Jaiswal\n",
      "Address : Sangam Vihar, New Delhi – 110080\n",
      "----------------------------------------------------------------------------------------\n",
      "Professional Summary\n",
      "Results-driven Business Analyst with a strong foundation in sales, business operations, and\n",
      "business process modelling, currently pursuing an MBA in Business Analytics. Skilled in data\n",
      "analysis, visualization, and predictive modeling, with hands-on experience in Python, SQL,\n",
      "Power BI, and Tableau. Demonstrated ability to deliver actionable insights through real-world\n",
      "projects in sentiment analysis, event analytics, and price prediction. Adept at bridging\n",
      "business needs and technical solutions, optimizing processes, and engaging key stakeholders\n",
      "to drive growth and informed decision-making.\n",
      "Education\n",
      "2024-26 Amity University Online, Noida 8.52*/10\n",
      "Master of Business Administration in Business Analytics\n",
      "2020-23 Indira Gandhi National Open University, New Delhi 65/100\n",
      "Bachelor’s Of Arts Economics Honours\n",
      "2018-20 Delhi Pharmaceutical Science And Research University, New Delhi 71/100\n",
      "Diploma in Pharmacy\n",
      "2016-18 12th (Senior Secondary Examination) 85/100\n",
      "Central Board of Secondary Education\n",
      "-2016 10th (Secondary Examination) 9.2/10\n",
      "Central Board of Secondary Education\n",
      "Experience\n",
      "Jan’2024- Business Officer, Zydus Healthcare Pvt Ltd., New Delhi\n",
      "• Led territory sales efforts, achieving 100%+ of sales targets and driving sustainable business\n",
      "growth.\n",
      "• Coordinated with management and cross-functional teams to align sales strategies with\n",
      "organizational goals.\n",
      "• Guided and mentored team members on client engagement, product knowledge, and\n",
      "territory management best practices.\n",
      "• Delivered actionable sales insights and territory analysis, enabling informed decision-\n",
      "making for the team and management.\n",
      "• Organized awareness campaigns and CME (Continuing Medical Education) sessions,\n",
      "fostering stronger customer relationships and brand trust.\n",
      "• Engaged 95% of key opinion leaders (KOLs) in the territory, strengthening partnerships and\n",
      "maximizing reach.\n",
      "Sep’2022- Territory Sales Officer, Pharmed Ltd., New Delhi\n",
      "Dec’2023 • Delivered 100% sales achievement with 95% key opinion leader engagement,\n",
      "strengthening management ties and ensuring long-term territory growth.\n",
      "Jul’2021- Medical Representative, Aristo Pharmaceuticals Pvt Ltd., New Delhi\n",
      "Aug’2022 • Started career as a Medical Representative, surpassing 101% of the target in the first\n",
      "quarter and showcasing strong initial performance.\n",
      "Academic Projects\n",
      "Jan’25- Mahakumbh Footfall Dashboard Link\n",
      "• Cleaned and structured large, inconsistent event datasets to uncover meaningful\n",
      "demographic and visitor patterns.\n",
      "• Developed an interactive Power BI dashboard highlighting peak footfall hours and key\n",
      "audience segments, enabling better event planning and resource allocation.\n",
      "Flipkart Reviews Sentiment Analysis Link\n",
      "• Scraped and processed product reviews using Python (Selenium, BeautifulSoup), handling\n",
      "noisy and imbalanced sentiment data effectively.\n",
      "• Built and optimized a sentiment classification model using NLP techniques and XGBoost,\n",
      "and presented actionable insights for improving customer experience using EDA.\n",
      "Cars24 Car Price Prediction Link\n",
      "• Addressed multicollinearity and missing values in the dataset to ensure robust predictive\n",
      "performance.\n",
      "• Engineered features and developed a regression model in Python, achieving ~0.85 R², and\n",
      "explained key drivers of car pricing to stakeholders.\n",
      "Technical Skills\n",
      "Programming Python (pandas, numpy, selenium, scikit-learn), SQL\n",
      "Data Power BI, Tableau, Excel (advanced)\n",
      "Visualization\n",
      "Web & Web scraping (Selenium, BeautifulSoup), API integration\n",
      "Automation\n",
      "Machine Regression models, Classification models, feature engineering, model evaluation (R², etc.)\n",
      "Learning\n",
      "Other Tools & ETL processes, Data cleaning & transformation, Microsoft Office Suite, Stakeholders\n",
      "Skills Management, Statistical analysis\n",
      "Certifications\n",
      "Oct’23-Apr’24 Certified in Basics of Python, Data Structures & Algorithms (DSA) from Coding Ninjas.\n",
      "Apr-Dec’24 Certified in Data Science & Machine Learning from Coding Ninjas, gaining hands-on\n",
      "experience with real-world datasets and predictive modeling.\n",
      "Jun’24 Completed the Deloitte Data Analytics Virtual Job Simulation on Forage, showcasing\n",
      "practical skills in data analysis, business problem-solving, and presenting actionable insights.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###put the path of skill library u have downloaded\n",
    "\n",
    "###if facing error try to install pdfplumber first by commanding %pip install pdfplumber\n",
    "\n",
    "lib_path=r\"C:\\Users\\wwwja\\Downloads\\archive\\skills.csv\"\n",
    "\n",
    "\n",
    "###your resume path\n",
    "\n",
    "pdf_path = r\"C:\\Users\\wwwja\\Downloads\\Ankush_Jaiswal_resume.pdf\"\n",
    "\n",
    "\n",
    "#### Put the job dDescription in below cell with three coloun to convert into string\n",
    "Description=\"\"\"Highly focused individual with self-driven attitude\n",
    "Problem-solving and logical thinking to automate and improve internal processes\n",
    "Using various tools such as SQL and Python for managing the various requirements for different data asset projects\n",
    "Ability to diligently involve in activities like Data Cleaning, Retrieval, Manipulation, Analytics, and Reporting\n",
    "Using data science and statistical techniques to build machine learning models and deal with textual data\n",
    "Keep up-to-date knowledge of the industry and related markets\n",
    "Ability to multitask, prioritize, and manage time efficiently\n",
    "Understand needs of the hiring organization or client in order to target solutions to their benefit\n",
    "Advanced speaking and writing skills for effective communication\n",
    "Ability to work in cross-functional teams demonstrating high level of commitment and coordination\n",
    "Attention to details and commitment to accuracy for the desired deliverable\n",
    "Should demonstrate and develop a sense of ownership toward the assigned task\n",
    "Ability to keep sensitive business information confidential\n",
    "Contribute, positively and extensively towards building the organizational reputation, brand, and operational excellence\n",
    "\n",
    "\n",
    "Desired Qualifications for Associate Data Scientist:\n",
    "\n",
    "\n",
    "\n",
    "3-6 years of relevant experience in data science\n",
    "Advanced knowledge of statistics and the basics of machine learning\n",
    "Experience in dealing with textual data and using natural language processing techniques\n",
    "Ability to conduct analysis to extract actionable insights\n",
    "Technical skills in Python (Numpy, Pandas, NLTK, transformers, Spacy), SQL, and other programming languages for dealing with large datasets\n",
    "Experience in data cleaning, manipulation, feature engineering, and building models\n",
    "Experience in the end-to-end development of a data science project\n",
    "Strong interpersonal skills and extremely resourceful\n",
    "Proven ability to complete assigned tasks according to the outlined scope and timeline\n",
    "Good language, communication, and writing skills in English\n",
    "Expertise in using tools like MS Office, PowerPoint, Excel, and Word\n",
    "Graduate or Post-graduate from a reputed college or university\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Run everything\n",
    "\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    text = \"\"\n",
    "    for page in pdf.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "\n",
    "print(text)\n",
    "##this print will return whether your resume has been parsed properly by the ppdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4fbe6fe-41a5-4188-a1ee-0f2e334bc131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e3c92-c89b-4c2d-977a-13a79a66dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##run the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dcd1629-dc6d-4e37-991a-558581b6ee8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:Ankush Kumar Jaiswal\n",
      "E-mail Id:jaiswalank1999@gmail.com\n",
      "Linkedin :https://www.linkedin.com/in/ankush-kumar-jaiswal-196937200\n",
      "Percentage of job Match: 48.07692307692308%\n",
      "Skills That Do Not Match: 3, 6, building, building models, business information, communication, contribute, english, hiring, interpersonal skills, language processing, languages, natural language, natural language processing, nltk, operational excellence, organization, ownership, powerpoint, processing, programming languages, project, reporting, spacy, statistics, word, writing\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(lib_path)\n",
    "df[\"Skill\"]=df[\"Skill\"].str.replace(\"\\n\", \"\", regex=True)\n",
    "Known_skills=df[\"Skill\"].to_list()\n",
    "\n",
    "# Read the PDF text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Extract name (assume first line is name if no header)\n",
    "def extract_name(text):\n",
    "    first_line = text.strip().split('\\n')[0]\n",
    "    return first_line\n",
    "\n",
    "# Extract email\n",
    "def extract_email(text):\n",
    "    match = re.findall(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "    return list(match)[0]\n",
    "\n",
    "# Extract phone number\n",
    "def extract_phone(text):\n",
    "    pattern = r\"(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{3,4}\\)?[-.\\s]?)?\\d{3,4}[-.\\s]?\\d{4}\"\n",
    "    match = re.findall(pattern, text)\n",
    "    phones = [\"\".join(m) for m in match]\n",
    "    return list(set(phones))[1]\n",
    "\n",
    "# Extract LinkedIn\n",
    "def extract_linkedin(text):\n",
    "    match = re.findall(r\"(https?://(www\\.)?linkedin\\.com/in/[A-Za-z0-9_-]+)\", text)\n",
    "    return [m[0] for m in match][0]\n",
    "\n",
    "# Extract location (very approximate: look for words like city, state or pin)\n",
    "def extract_location(text):\n",
    "    # you may replace this with your list of cities or patterns\n",
    "    pattern = r\"(?:\\b[A-Z][a-z]*(?:\\s+[A-Z][a-z]*)*(?:,)?\\s*)+[–-]?\\s*\\d{6}\"\n",
    "    match = re.findall(pattern, text)\n",
    "\n",
    "    if match:\n",
    "        return match[0]\n",
    "    return []\n",
    "\n",
    "# Extract education (look for degrees)\n",
    "def extract_education(text):\n",
    "    education_keywords = [\n",
    "    \"Bachelor\", \"Bachelors\", \"Bachelor's\",\n",
    "    \"Master\", \"Masters\", \"Master's\",\n",
    "    \"B\\.Sc\", \"M\\.Sc\", \"MBA\", \"PhD\", \"Diploma\", \"B\\.Tech\", \"M\\.Tech\"\n",
    "]\n",
    "\n",
    "\n",
    "    lines = text.split('\\n')\n",
    "    education = []\n",
    "    in_education_section = False\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        line_lower = line.strip().lower()\n",
    "\n",
    "        # Look for education section header\n",
    "        if re.search(r'education|academic background|educational qualifications', line_lower):\n",
    "            in_education_section = True\n",
    "            continue\n",
    "\n",
    "        # Stop if we reach another section\n",
    "        if in_education_section and re.search(r'(experience|skills|projects|certifications|summary|profile)', line_lower):\n",
    "            break\n",
    "\n",
    "        # If inside education section, look for degrees\n",
    "        if in_education_section:\n",
    "            for k in education_keywords:\n",
    "                if re.search(k, line, re.IGNORECASE):\n",
    "                    education.append(line.strip())\n",
    "                    break\n",
    "\n",
    "    return education\n",
    "\n",
    "def extract_skills(text, known_skills):\n",
    "    \"\"\"\n",
    "    Extract skills from full text after cleaning it.\n",
    "    Matches only known skills.\n",
    "    \"\"\"\n",
    "    found_skills = set()\n",
    "\n",
    "    # Lowercase & clean text\n",
    "    text_clean = text.lower()\n",
    "    # Remove unwanted characters: (),., commas, etc.\n",
    "    text_clean = re.sub(r'[(),.]', ' ', text_clean)\n",
    "    # Replace multiple spaces with single space\n",
    "    text_clean = re.sub(r'\\s+', ' ', text_clean)\n",
    "\n",
    "    for skill in known_skills:\n",
    "        # Match skill in cleaned text\n",
    "        if re.search(rf'\\b{re.escape(skill.lower())}\\b', text_clean):\n",
    "            found_skills.add(skill)\n",
    "\n",
    "    found_skills= list(dict.fromkeys(found_skills))\n",
    "\n",
    "\n",
    "    return sorted(found_skills)\n",
    "\n",
    "\n",
    "\n",
    "def extract_certifications(text):\n",
    "    certifications = []\n",
    "    lines = text.split('\\n')\n",
    "    in_cert_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        line_lower = line.strip().lower()\n",
    "\n",
    "        # Detect certifications section header\n",
    "        if re.search(r'(certifications?|licenses|accreditations)', line_lower):\n",
    "            in_cert_section = True\n",
    "            continue\n",
    "\n",
    "        # Stop at next section header\n",
    "        if in_cert_section and re.search(\n",
    "            r'(experience|education|skills|projects|summary|profile|work|achievements)', \n",
    "            line_lower\n",
    "        ):\n",
    "            break\n",
    "\n",
    "        # If inside certifications section, and line is not empty\n",
    "        if in_cert_section:\n",
    "            if line.strip():\n",
    "                certifications.append(line.strip())\n",
    "\n",
    "    return certifications\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "data = {\n",
    "    \"name\": extract_name(text),\n",
    "    \"email\": extract_email(text),\n",
    "    \"phone\": extract_phone(text),\n",
    "    \"linkedin\": extract_linkedin(text),\n",
    "    \"location\": extract_location(text),\n",
    "    \"education\": extract_education(text),\n",
    "    \"skills\": extract_skills(text, Known_skills), \n",
    "    \"certification\": extract_certifications(text)\n",
    "}\n",
    "\n",
    "def extract_skills_from_jd(text, known_skills):\n",
    "    \"\"\"\n",
    "    Extract key skills mentioned in a LinkedIn job description.\n",
    "\n",
    "    :param text: The job description text (string)\n",
    "    :param known_skills: (optional) a predefined list of skills to match against\n",
    "    :return: list of detected skills\n",
    "    \"\"\"\n",
    "    # Lowercase the text for uniformity\n",
    "    text_lower = text.lower()\n",
    "\n",
    "\n",
    "    found_skills = set()\n",
    "\n",
    "    for skill in known_skills:\n",
    "        # use word boundaries to avoid partial matches\n",
    "        if re.search(rf'\\b{re.escape(skill)}\\b', text_lower):\n",
    "            found_skills.add(skill)\n",
    "    found_skills=list(dict.fromkeys(found_skills))\n",
    "\n",
    "\n",
    "    return sorted(found_skills)\n",
    "\n",
    "def report(ans, data):\n",
    "    not_matched_skills=[]\n",
    "    count=0\n",
    "\n",
    "    for i in ans:\n",
    "        if i in data[\"skills\"]:\n",
    "            count += 1\n",
    "\n",
    "        else:\n",
    "            not_matched_skills.append(i)\n",
    "    Percent_job_match=(count/len(ans))*100\n",
    "    return Percent_job_match, not_matched_skills\n",
    "ans=extract_skills_from_jd(Description, Known_skills)\n",
    "percent, not_match=report(ans, data)\n",
    "print(f\"Name:{data[\"name\"]}\")\n",
    "print(f\"E-mail Id:{data[\"email\"]}\")\n",
    "print(f\"Linkedin :{data[\"linkedin\"]}\")\n",
    "\n",
    "print(f\"Percentage of job Match: {percent}%\")\n",
    "print(f\"Skills That Do Not Match: {\", \".join(not_match)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37ed20-ad8e-4bfd-af6d-ef985c02643b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
